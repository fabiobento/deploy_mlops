Adaptado de [Machine Learning in Production](https://www.deeplearning.ai/courses/machine-learning-in-production/) de [Andrew Ng](https://www.deeplearning.ai/)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/))

# Introdu√ß√£o a Kubernetes
Nesse laborat√≥rio utilizaremos o Kubernetes e, antes de prosseguir, recomendo que voc√™ d√™ uma olhada em como ele funciona. O site √©
https://kubernetes.io/
e, na parte superior da p√°gina, h√° um grande bot√£o que diz "*Learn Kubernetes Basics*" (Aprenda o b√°sico do Kubernetes).
<img src='img/introk8s.png ' alt='img/kubernetes.png'>

Clique nele e voc√™ ser√° direcionado para: 
https://kubernetes.io/docs/tutorials/kubernetes-basics/

A partir da√≠, voc√™ pode passar por um tutorial de como criar um cluster, implantar um aplicativo, dimension√°-lo, atualiz√°-lo e muito mais. √â interativo, divertido e vale a pena dedicar algumas horas do seu tempo para realmente entender como o Kubernetes funciona.

Talvez voc√™ tamb√©m queira conferir este [tutorial em v√≠deo](https://youtu.be/H06qrNmGqyE). 

# Pratique o Kubernetes em seu ambiente local

No item anterior, voc√™ viu os conceitos b√°sicos do Kubernetes executando comandos imperativos no shell interativo (ou seja, com o `kubectl`). Ele mostra como essa ferramenta pode ser usada para orquestrar cont√™ineres para hospedar um aplicativo. Se voc√™ n√£o tiver feito esse exerc√≠cio, recomendamos que volte a ele, pois presumiremos que voc√™ j√° esteja familiarizado com os conceitos discutidos [naqueles 6 m√≥dulos](https://kubernetes.io/docs/tutorials/kubernetes-basics/). Este laborat√≥rio ser√° uma extens√£o dessa atividade e mostrar√° mais alguns conceitos. Especificamente, voc√™ ir√°:

* configurar o Kubernetes em seu computador local para aprendizado e desenvolvimento
* create Kubernetes objects using YAML files
* criar objetos do Kubernetes usando arquivos YAML
* acessar a implanta√ß√£o usando um servi√ßo Nodeport
* dimensionar automaticamente a implanta√ß√£o para lidar dinamicamente com o tr√°fego de entrada 

## Instala√ß√£o

Primeiro, voc√™ configurar√° sua m√°quina para executar um cluster local do Kubernetes. Isso lhe d√° mais liberdade para ajustar as configura√ß√µes e implementar mais recursos em compara√ß√£o com o ambiente Katacoda on-line que voc√™ usou no tutorial do Kubernetes. √â uma √≥tima ferramenta para aprendizado e tamb√©m para desenvolvimento local. H√° v√°rias distribui√ß√µes do Kubernetes e a mais adequada para nosso objetivo √© a [Minikube](https://minikube.sigs.k8s.io/docs/). Voc√™ deve se lembrar que ela foi mencionada no primeiro m√≥dulo do exerc√≠cio b√°sico do Kubernetes.

Voc√™ precisar√° instalar as seguintes ferramentas para realizar este laborat√≥rio:

* **curl** - uma ferramenta de linha de comando para transfer√™ncia de dados usando v√°rios protocolos de rede. √â poss√≠vel que voc√™ j√° tenha instalado isso anteriormente, mas, caso n√£o tenha, [aqui est√° uma refer√™ncia](https://reqbin.com/Article/InstallCurl) para fazer isso. Voc√™ usar√° isso para consultar seu modelo mais tarde.

* **Docker** - O Minikube foi projetado para ser executado virtualizado em uma VM ou container. Por isso vamos utilizar o [Docker](https://docs.docker.com/engine/install/) 18.09 or higher (20.10 ou superior √© o remcomentado).

* **kubectl** - a ferramenta de linha de comando para interagir com clusters do Kubernetes. As instru√ß√µes de instala√ß√£o podem ser encontradas [aqui](https://kubernetes.io/docs/tasks/tools/).

* **Minikube** - uma distribui√ß√£o do Kubernetes voltada para novos usu√°rios e trabalho de desenvolvimento. No entanto, ela n√£o se destina a implementa√ß√µes de produ√ß√£o, pois s√≥ pode executar um cluster de n√≥ √∫nico em sua m√°quina. Instru√ß√µes de instala√ß√£o [aqui](https://minikube.sigs.k8s.io/docs/start/).

## Arquitetura
A aplica√ß√£o que voc√™ criar√° ser√° parecida com a figura abaixo

<img src='img/kubernetes.png' alt='img/kubernetes.png'>

Voc√™ criar√° uma implanta√ß√£o que ativa cont√™ineres que executam um servidor de modelo. Neste caso, ele ser√° da imagem `tensorflow/serving`. A implanta√ß√£o pode ser acessada por terminais externos (ou seja, seus usu√°rios) por meio de um servi√ßo exposto. Isso traz solicita√ß√µes de infer√™ncia para os servidores de modelo e responde com previs√µes do seu modelo.

Por fim, a implanta√ß√£o ativar√° ou desativar√° os pods com base na utiliza√ß√£o da CPU. Ele come√ßar√° com um pod, mas quando a carga exceder um ponto predefinido, ele ativar√° pods adicionais para compartilhar a carga.

## Iniciar o Minikube

Agora voc√™ est√° quase pronto para iniciar seu cluster do Kubernetes. H√° apenas mais uma etapa adicional. Como mencionado anteriormente, o Minikube √© executado dentro de uma m√°quina virtual. Isso significa que os pods que voc√™ criar√° posteriormente s√≥ ver√£o os volumes dentro dessa VM. Portanto, se voc√™ quiser carregar um modelo em seus pods, dever√° primeiro montar o local desse modelo dentro da VM do Minikube. Vamos configurar isso agora.

Voc√™ usar√° o modelo `half_plus_two` que viu anteriormente. Voc√™ pode copi√°-lo para o diret√≥rio `/var/tmp`. Voc√™ pode usar o comando abaixo:

```
cp -R ./saved_model_half_plus_two_cpu /var/tmp
```
Agora voc√™ est√° pronto para iniciar o Minikube! Execute o comando abaixo para inicializar o Virtualbox e montar a pasta que cont√©m seu arquivo de modelo:
   ```
   minikube start --mount=True --mount-string="/var/tmp:/var/tmp" --vm-driver=docker
  ```


---

</details>
</br>

## Cria√ß√£o de objetos com arquivos YAML

No tutorial b√°sico oficial do Kubernetes, voc√™ usou principalmente o `kubectl` para criar objetos como pods, implanta√ß√µes e servi√ßos. Embora isso definitivamente funcione, sua configura√ß√£o ser√° mais port√°til e mais f√°cil de manter se voc√™ configur√°-los usando arquivos [YAML](https://yaml.org/spec/1.2/spec.html). Inclu√≠ esses arquivos no diret√≥rio `yaml` deste laborat√≥rio para que voc√™ possa ver como eles s√£o criados. A [Kubernetes API](https://kubernetes.io/docs/reference/kubernetes-api/) tamb√©m documenta os campos compat√≠veis com cada objeto. Por exemplo, a API para Pods pode ser encontrada [aqui](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/).

Uma maneira de gerar isso quando voc√™ n√£o tem um modelo para come√ßar √© usar primeiro o comando `kubectl` e, em seguida, usar o sinalizador `-o yaml` para gerar o arquivo YAML para voc√™. Por exemplo, o [kubectl cheatsheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/) mostra que voc√™ pode gerar o YAML para um pod executando uma imagem `nginx` com esse comando:

```
kubectl run nginx --image=nginx --dry-run=client -o yaml > pod.yaml
```

Todos os objetos necess√°rios para este laborat√≥rio j√° foram fornecidos e voc√™ pode modific√°-los posteriormente quando quiser praticar configura√ß√µes diferentes. Vamos examin√°-los um a um nas pr√≥ximas se√ß√µes.

### Config Maps

Primeiro, voc√™ criar√° um [config map](https://kubernetes.io/docs/concepts/configuration/configmap/) que define uma vari√°vel `MODEL_NAME` e `MODEL_PATH`. Isso √© necess√°rio devido ao modo como a imagem `tensorflow/serving` √© configurada. Se voc√™ observar a √∫ltima camada do arquivo docker [aqui](https://hub.docker.com/layers/tensorflow/serving/2.6.0/images/sha256-7e831f11c9ef928c09b4064a059066484079ac819991f162a938de0ad4b0fbd5?context=explore), ver√° que ele executa um script `/usr/bin/tf_serving_entrypoint.sh` quando inicia o cont√™iner. Esse script cont√©m apenas esse comando:

```
#!/bin/bash 

tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} "$@"
```

Basicamente, ele inicia o servidor de modelos e usa as vari√°veis de ambiente `MODEL_BASE_PATH` e `MODEL_NAME` para localizar o modelo. Embora voc√™ tamb√©m possa definir isso explicitamente no arquivo YAML `Deployment`, seria mais organizado t√™-lo em um configmap para que voc√™ possa conect√°-lo posteriormente. Abra `yaml/configmap.yaml` para ver a sintaxe.

Voc√™ pode criar o objeto agora usando o `kubectl`, conforme mostrado abaixo. Observe o sinalizador `-f` para especificar um nome de arquivo. Voc√™ tamb√©m pode especificar um diret√≥rio, mas faremos isso mais tarde.

```
kubectl apply -f yaml/configmap.yaml
```

Com isso, voc√™ deve ser capaz de "obter" e "descrever" o objeto como antes. Por exemplo, `kubectl describe cm tfserving-configs` deve mostrar a voc√™:

```
Name:         tfserving-configs
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
MODEL_PATH:
----
/models/half_plus_two
MODEL_NAME:
----
half_plus_two
Events:  <none>
```

### Criar um Deployment

Agora, voc√™ criar√° a implementa√ß√£o do seu aplicativo. Abra `yaml/deployment.yaml` para ver a especifica√ß√£o desse objeto. Voc√™ ver√° que ele inicia uma r√©plica, usa `tensorflow/serving` como a imagem do cont√™iner e define vari√°veis de ambiente por meio da tag `envFrom`. Ele tamb√©m exp√µe a porta `8501` do cont√™iner porque voc√™ enviar√° solicita√ß√µes HTTP a ele mais tarde. Ele tamb√©m define os limites de CPU e mem√≥ria e monta o volume da VM do Minikube para o cont√™iner.

Como antes, voc√™ pode aplicar esse arquivo para criar o objeto:

```
kubectl apply -f yaml/deployment.yaml
```

A execu√ß√£o de `kubectl get deploy` ap√≥s cerca de 90 segundos deve mostrar algo como o que est√° abaixo para informar que a implanta√ß√£o est√° pronta.

```
NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
tf-serving-deployment   1/1     1            1           15s
```

### Expor o deployment atrav√©s de um servi√ßo

Como voc√™ aprendeu anteriormente no tutorial do Kubernetes, ser√° necess√°rio criar um servi√ßo para que seu aplicativo possa ser acessado fora do cluster. Inclu√≠mos o `yaml/service.yaml` para isso. Ele define um servi√ßo [NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#nodeport) que exp√µe a porta 30001 do n√≥. As solicita√ß√µes enviadas para essa porta ser√£o enviadas para a `targetPort` especificada pelos cont√™ineres, que √© `8501`. 

Aplique `kubectl apply -f yaml/service.yaml` e execute `kubectl get svc tf-serving-service`. Voc√™ dever√° ver algo parecido com isto:

```
NAME                 TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
tf-serving-service   NodePort   10.103.30.4   <none>        8501:30001/TCP   27s
```

Voc√™ pode tentar acessar a implanta√ß√£o agora para uma verifica√ß√£o se est√° tudo funcionando bem. O comando `curl` a seguir enviar√° uma linha de solicita√ß√µes de infer√™ncia para o servi√ßo Nodeport:

```
curl -d '{"instances": [1.0, 2.0, 5.0]}' -X POST $(minikube ip):30001/v1/models/half_plus_two:predict
```

Se o comando acima n√£o funcionar, voc√™ pode executar `minikube ip` primeiro para obter o endere√ßo IP do n√≥ do Minikube. Ele deve retornar um endere√ßo IP local como `192.168.99.102` (se voc√™ vir `127.0.0.1`, consulte as se√ß√µes de solu√ß√£o de problemas abaixo). Voc√™ pode ent√£o inserir esse endere√ßo no comando acima substituindo a string `$(minikube ip)`. Por exemplo:

```
curl -d '{"instances": [1.0, 2.0, 5.0]}' -X POST http://192.168.99.102:30001/v1/models/half_plus_two:predict
```

<details>
<summary> <i> Solu√ß√£o de problemas: Clique aqui se voc√™ usou o Docker em vez do Virtualbox como o tempo de execu√ß√£o da VM </i> </summary>

Provavelmente, a conex√£o ser√° recusada aqui porque a rede ainda n√£o est√° configurada. Para contornar isso, execute este comando em uma janela separada: `minikube service tf-serving-service`. Voc√™ ver√° um resultado como o abaixo 

```
|-----------|--------------------|----------------------|---------------------------|
| NAMESPACE |        NAME        |     TARGET PORT      |            URL            |
|-----------|--------------------|----------------------|---------------------------|
| default   | tf-serving-service | tf-serving-http/8501 | http://192.168.20.2:30001 |
|-----------|--------------------|----------------------|---------------------------|
üèÉ  Starting tunnel for service tf-serving-service.
|-----------|--------------------|-------------|------------------------|
| NAMESPACE |        NAME        | TARGET PORT |          URL           |
|-----------|--------------------|-------------|------------------------|
| default   | tf-serving-service |             | http://127.0.0.1:60473 |
|-----------|--------------------|-------------|------------------------|
```

Isso abre um t√∫nel para seu servi√ßo com uma porta aleat√≥ria. Pegue o URL na caixa inferior direita e use-o no comando curl da seguinte:

```
curl -d '{"instances": [1.0, 2.0, 5.0]}' -X POST http://127.0.0.1:60473/v1/models/half_plus_two:predict
```

---

</details>
<br>

Se o comando for bem-sucedido, voc√™ ver√° os resultados retornados pelo modelo:

```
{
    "predictions": [2.5, 3.0, 4.5
    ]
}
```

Excelente! Seu aplicativo foi executado com sucesso e pode ser acessado fora do cluster!

### Horizontal Pod Autoscaler

Uma das grandes vantagens da orquestra√ß√£o de cont√™ineres √© que ela permite dimensionar o aplicativo de acordo com as necessidades do usu√°rio. O Kubernetes fornece um [Horizontal Pod Autoscaler (HPA)](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) para criar ou remover conjuntos de r√©plicas com base nas m√©tricas observadas. Para fazer isso, o HPA consulta um [Metrics Server](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server) para medir a utiliza√ß√£o de recursos, como CPU e mem√≥ria. O Metrics Server n√£o √© iniciado por padr√£o no Minikube e precisa ser ativado com o seguinte comando:

```
minikube addons enable metrics-server
```


Voc√™ dever√° ver um prompt dizendo ` The 'metrics-server' addon is enabled
`. Isso inicia uma implanta√ß√£o do `metrics-server` no namespace `kube-system`. Execute o comando abaixo e aguarde at√© que a implanta√ß√£o esteja pronta.



```
kubectl get deployment metrics-server -n kube-system
```

Voc√™ dever√° ver algo como:

```
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
metrics-server   1/1     1            1           76s
```

Com isso, agora voc√™ pode criar seu autoscaler aplicando `yaml/autoscale.yaml`. Aguarde cerca de um minuto para que ele possa consultar o servidor de m√©tricas. A execu√ß√£o de `kubectl get hpa` deve mostrar: 

```
NAME             REFERENCE                          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
tf-serving-hpa   Deployment/tf-serving-deployment   0%/2%    1         3         1          38s

```

Se estiver mostrando `Unknown` em vez de `0%` na coluna `TARGETS`, voc√™ pode tentar enviar alguns comandos curl como fez anteriormente e aguardar mais um minuto.


### Teste de Stress

Para testar o recurso de dimensionamento autom√°tico de sua implanta√ß√£o, fornecemos um script bash curto (`request.sh`) que enviar√° solicita√ß√µes de forma persistente ao seu aplicativo. Abra uma nova janela de terminal, certifique-se de que est√° no diret√≥rio raiz deste arquivo README e, em seguida, execute este comando (para Linux e Mac):

```
/bin/bash request.sh
```

<details>
<summary> <i>Solu√ß√£o de problemas: Clique aqui se voc√™ usou o Docker como driver de VM em vez do VirtualBox </i></summary>

Se estiver usando um t√∫nel minikube para o `tf-serving-service`, ser√° necess√°rio modificar o script bash para corresponder ao URL que voc√™ est√° usando. Abra o arquivo `request.sh` em um editor de texto e altere `$(minikube ip)` para o URL especificado no comando `minikube tunnel` anteriormente. Por exemplo:

```
#!/bin/bash

while sleep 0.01;

do curl -d '{"instances": [1.0, 2.0, 5.0]}' -X POST http://127.0.0.1:60473/v1/models/half_plus_two:predict;

done
``` 
---

</details>
</br>


Voc√™ dever√° ver os resultados sendo impressos em r√°pida sucess√£o:

```
{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{
    "predictions": [2.5, 3.0, 4.5
    ]
}{

```

Se estiver vendo uma conex√£o recusada, verifique se o servi√ßo ainda est√° em execu√ß√£o com `kubectl get svc tf-serving-service`.


H√° v√°rias maneiras de monitorar isso, mas a mais f√°cil seria usar o painel de controle integrado do Minikube. Voc√™ pode inici√°-lo executando:

```
minikube dashboard
```

Se voc√™ iniciou o processo imediatamente ap√≥s executar o script de solicita√ß√£o, dever√° ver inicialmente uma √∫nica r√©plica em execu√ß√£o na se√ß√£o `Deployments` e `Pods`:

<img src='img/initial_load.png'>

Ap√≥s cerca de um minuto de execu√ß√£o do script, voc√™ observar√° que a utiliza√ß√£o da CPU atingir√° de 5 a 6m. Isso √© mais do que os 20% que definimos no HPA e, portanto, acionar√° a ativa√ß√£o das r√©plicas adicionais:

<img src='img/autoscale_start.png'>

Finalmente, todos os tr√™s pods estar√£o prontos para aceitar solicita√ß√µes e compartilhar√£o a carga. Veja que cada pod abaixo mostra `2.00m` de uso da CPU.

<img src='img/autoscaled.png'>

Agora voc√™ pode interromper o script `request.sh` pressionando `Ctrl/Cmd + C`. Ao contr√°rio do aumento de escala, a redu√ß√£o do n√∫mero de pods levar√° mais tempo antes de ser executada. Voc√™ aguardar√° cerca de 5 minutos (quando a utiliza√ß√£o da CPU estiver abaixo de 1m) antes de ver que h√° apenas um pod em execu√ß√£o novamente. Esse √© o comportamento da vers√£o da API `autoscaling/v1` que estamos usando. J√° existe uma vers√£o `v2` em fase beta sendo desenvolvida para substituir esse comportamento e voc√™ pode ler mais sobre ela [aqui](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#api-object).

## Tear Down

Quando terminar de experimentar, voc√™ poder√° destruir os recursos que criou, se desejar. Voc√™ pode simplesmente chamar `kubectl delete -f yaml` para excluir todos os recursos definidos na pasta `yaml`. Voc√™ ver√° algo parecido com isto:

```
horizontalpodautoscaler.autoscaling "tf-serving-hpa" deleted
configmap "tfserving-configs" deleted
deployment.apps "tf-serving-deployment" deleted
service "tf-serving-service" deleted
```

Voc√™ pode recriar todos eles na pr√≥xima vez com um √∫nico comando executando `kubectl apply -f yaml`. Lembre-se apenas de verificar se o `metrics-server` est√° ativado e em execu√ß√£o.

Se voc√™ tamb√©m quiser destruir a VM, poder√° executar o comando `minikube delete`. 

Se voc√™ usou o Powershell, poder√° desativar o scripting conforme mencionado nas instru√ß√µes anteriores.

## Resumo

Neste laborat√≥rio, voc√™ praticou mais no√ß√µes b√°sicas do Kubernetes usando arquivos de configura√ß√£o YAML e executando o cont√™iner Tensorflow Serving. Essa pode ser uma linha de base para voc√™ come√ßar a tentar atender aos seus pr√≥prios modelos com uma estrutura de orquestra√ß√£o em mente. A maioria dos conceitos aqui ser√° aplic√°vel ao Qwiklabs desta semana, portanto, fique √† vontade para consultar este documento. Bom trabalho e vamos para a pr√≥xima parte do curso!

