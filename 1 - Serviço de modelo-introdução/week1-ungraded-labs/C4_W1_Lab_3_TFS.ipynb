{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptado de [Machine Learning in Production](https://www.deeplearning.ai/courses/machine-learning-in-production/) de [Andrew Ng](https://www.deeplearning.ai/)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Servir um modelo com o TensorFlow Serving\n",
    "------------------------\n",
    "\n",
    "Neste laboratório, você dará uma olhada no sistema de fornecimento de modelos da TFX para produção chamado [Tensorflow Serving](https://www.tensorflow.org/tfx/guide/serving). Esse sistema é altamente integrado ao Tensorflow e oferece uma maneira fácil e direta de implantar modelos.\n",
    "\n",
    "Especificamente, você irá:\n",
    "- Aprender a instalar o TF Serving.\n",
    "- Carregar um modelo pré-treinado que classifica cães, pássaros e gatos.\n",
    "- Salve-o seguindo as convenções necessárias para o TF serving.\n",
    "- Rodar um servidor Web usando o TF serving que aceitará solicitações por HTTP.\n",
    "- Ingeragir com seu modelo por meio de uma API REST.\n",
    "- Saiba mais sobre o controle de versão do modelo.\n",
    "\n",
    "Este laboratório se inspira [nesse tutorial oficial do Tensorflow](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), portanto, consulte-o se tiver dúvidas sobre os tópicos abordados aqui.\n",
    "\n",
    "Observe que, diferentemente do último laboratório, você trabalhará com o TF servindo sem usar o Docker. O objetivo é mostrar a você as diferentes maneiras de usar esse sistema de serviço.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXp_5RW_dO7k"
   },
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Guf4H620nSWU"
   },
   "source": [
    "### Baixando os dados\n",
    "\n",
    "Neste laboratório, você não treinará um modelo, mas usará um modelo para obter previsões, por isso precisa de algumas imagens de teste. O modelo que você usará foi originalmente treinado com imagens dos conjuntos de dados *cats and dogs* e  *Caltech birds*. Para solicitar previsões, são fornecidas algumas imagens do conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x02JYzMgfTB"
   },
   "outputs": [],
   "source": [
    "# Baixar as imagens\n",
    "!wget -q https://storage.googleapis.com/mlep-public/course_3/week2/images.zip\n",
    "\n",
    "# Definir o diretório base\n",
    "base_dir = '/tmp/data'\n",
    "\n",
    "# Descompactar as imagens\n",
    "with zipfile.ZipFile('/content/images.zip', 'r') as my_zip:\n",
    "  my_zip.extractall(base_dir)\n",
    "\n",
    "# Salvar os caminhos para as imagens de cada classe\n",
    "dogs_dir = os.path.join(base_dir, 'images/dogs')\n",
    "cats_dir = os.path.join(base_dir,'images/cats')\n",
    "birds_dir = os.path.join(base_dir,'images/birds')\n",
    "\n",
    "# Imprimir a quantidade de imagens de cada classe\n",
    "print(f\"Há {len(os.listdir(dogs_dir))} imagens de cachorros\")\n",
    "print(f\"Há {len(os.listdir(cats_dir))} imagens de gatos\")\n",
    "print(f\"Há {len(os.listdir(birds_dir))} imagens de pássaros\\n\\n\")\n",
    "\n",
    "# Veja exemplos de imagens de cada classe\n",
    "print(\"Exemplo de imagem de gato:\")\n",
    "display(Image(filename=f\"{os.path.join(cats_dir, os.listdir(cats_dir)[0])}\"))\n",
    "print(\"\\nExemplo de imagen de cachorro:\")\n",
    "display(Image(filename=f\"{os.path.join(dogs_dir, os.listdir(dogs_dir)[0])}\"))\n",
    "print(\"\\nExemplo de imagem de pássaro:\")\n",
    "display(Image(filename=f\"{os.path.join(birds_dir, os.listdir(birds_dir)[0])}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aEMMrP1oyfx"
   },
   "source": [
    "Agora que você está familiarizado com os dados com os quais trabalhará, vamos passar para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jAk1ZXqTJqN"
   },
   "source": [
    "### Carregar um modelo pré-treinado\n",
    "\n",
    "O objetivo deste laboratório é demonstrar os recursos do TF serving, portanto, você não investirá tempo treinando um modelo. Em vez disso, você usará um modelo pré-treinado. Esse modelo classifica imagens de pássaros, gatos e cachorros e foi treinado com aumento de imagem para produzir resultados muito bons.\n",
    "\n",
    "Primeiro, faça o download dos arquivos necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJuNJRCDdR6J"
   },
   "outputs": [],
   "source": [
    "!wget -q -P /content/model/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/saved_model.pb\n",
    "!wget -q -P /content/model/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.data-00000-of-00001\n",
    "!wget -q -P /content/model/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv3Rlpvde9g9"
   },
   "source": [
    "Agora, carregue o modelo na memória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQX6BPAVdiwg"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAjBnjuqfGuS"
   },
   "source": [
    "Neste ponto, você pode presumir que treinou o modelo com sucesso. Você pode ignorar os avisos sobre o modelo ter sido treinado em uma versão mais antiga do TensorFlow.\n",
    "\n",
    "Para fins de contexto, esse modelo usa uma arquitetura CNN simples. Dê uma olhada rápida nas camadas que o compõem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWkoEffIdwLQ"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwGPItyphqXT"
   },
   "source": [
    "## Salve seu modelo\n",
    "\n",
    "Para carregar nosso modelo treinado no TensorFlow Serving, primeiro precisamos salvá-lo no formato [SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/saved_model).\n",
    "\n",
    "Isso criará um arquivo [protobuf](https://developers.google.com/protocol-buffers) em uma hierarquia de diretórios bem definida e incluirá um número de versão.\n",
    "\n",
    "O [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) nos permite selecionar qual versão de um modelo, ou \"servível\", queremos usar quando fizermos solicitações de inferência.\n",
    "\n",
    "Cada versão será exportada para um subdiretório diferente no caminho fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0w5Rq8SsgWE6"
   },
   "outputs": [],
   "source": [
    "# Buscar a sessão do Keras e salvar o modelo\n",
    "# A definição da assinatura é definida pelos tensores de entrada e saída,\n",
    "# e armazenada com a chave de serviço padrão\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print(f'export_path = {export_path}\\n')\n",
    "\n",
    "\n",
    "# Salvar o modelo\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLieWFZzqzoC"
   },
   "source": [
    "Um modelo salvo em disco inclui os seguintes arquivos:\n",
    "- `assets`: um diretório que inclui arquivos arbitrários usados pelo grafo TF.\n",
    "- `variables`: um diretório que contém informações sobre os pontos de verificação de treinamento do modelo.\n",
    "- `saved_model.pb`: o arquivo protobuf que representa o programa TF real.\n",
    "\n",
    "Dê uma olhada rápida nesses arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-1ARuKsqDpN"
   },
   "outputs": [],
   "source": [
    "print(f'\\nArquivos do modelo salvos em {export_path }:\\n')\n",
    "!ls -lh {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM7B_RuDYoIj"
   },
   "source": [
    "## Examine seu modelo salvo\n",
    "\n",
    "Usaremos o utilitário de linha de comando `saved_model_cli` para examinar os [MetaGraphDefs](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/MetaGraphDef) (os modelos) e [SignatureDefs](https://www.tensorflow.org/tfx/serving/signature_defs) (os métodos que você pode chamar) em nosso SavedModel.\n",
    "\n",
    "Para maiores detalhes consulte [essa discussão sobre a CLI do SavedModel](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel) no Guia do TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LU4GDF_aYtfQ"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSPWuegUb7Eo"
   },
   "source": [
    "Isso nos diz muito sobre o nosso modelo!\n",
    "\n",
    "Nesse caso, não treinamos explicitamente o modelo, portanto, qualquer informação sobre as entradas e saídas é muito valiosa. \n",
    "\n",
    "Por exemplo, sabemos que esse modelo espera que nossas entradas tenham a forma `(150, 150, 3)`, o que, combinado com o uso de camadas `conv2d`, sugere que esse modelo espera imagens coloridas em uma resolução de `150 por 150`.\n",
    "\n",
    "Além disso, a saída do modelo tem a forma `(3)`, o que sugere uma ativação `softmax` com 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2IJklPdvb4q"
   },
   "source": [
    "## Preparar dados para inferência\n",
    "\n",
    "Agora que você conhece a forma dos dados esperados pelo modelo, é hora de pré-processar as imagens de teste adequadamente. \n",
    "\n",
    "Essas imagens são fornecidas em uma ampla variedade de resoluções, e felizmente o Keras tem o que você precisa com seu [`ImageDataGenerator`](https://keras.io/api/preprocessing/image/).\n",
    "\n",
    "Usando esse objeto, você pode:\n",
    "- Normalizar valores de pixel.\n",
    "- Padronizar resoluções de imagem.\n",
    "- Definir um tamanho de lote para inferência.\n",
    "- E muito mais!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcnU-SjhvYEX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalizar os valores dos pixels\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Apontar para o diretório com as imagens de teste\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/images',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "# Imprimir o rótulo associado a cada classe\n",
    "print(f\"Os rótulos de cada classe no gerador de testes são: {val_gen_no_shuffle.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvw4doL20UeK"
   },
   "source": [
    "Como esse objeto é um [gerador](https://wiki.python.org/moin/Generators), você pode obter um lote de imagens e rótulos usando a função `next`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGaajm_F0Jd8"
   },
   "outputs": [],
   "source": [
    "# Obtenha um lote de 32 imagens junto com seu rótulo verdadeiro\n",
    "data_imgs, labels = next(val_gen_no_shuffle)\n",
    "\n",
    "# Verifique os formatos\n",
    "print(f\"data_imgs tem formato: {data_imgs.shape}\")\n",
    "print(f\"os rótulos tem o formato: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MH3YPjZ1D8I"
   },
   "source": [
    "Como esperado, `data_imgs` é uma matriz que contém 32 imagens coloridas com resolução de 150x150. De maneira semelhante, `labels` tem o rótulo verdadeiro para cada uma dessas 32 imagens.\n",
    "\n",
    "Para verificar se tudo está funcionando corretamente, faça uma verificação de sanidade para plotar as primeiras 5 imagens do lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31yuK5RTvgkT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "# Retorna a representação em string de cada classe\n",
    "def get_class(index):\n",
    "  if index == 0:\n",
    "    return \"bird\"\n",
    "  elif index == 1:\n",
    "    return \"cat\"\n",
    "  elif index == 2:\n",
    "    return \"dog\"\n",
    "  return None\n",
    "\n",
    "\n",
    "# Plota uma matriz numpy que representa uma imagem\n",
    "def plot_array(array, label, pred=None):\n",
    "  array = np.squeeze(array)\n",
    "  img = array_to_img(array)\n",
    "  display(img)\n",
    "  if pred is None:\n",
    "    print(f\"A imagem mostra um {get_class(label)}.\\n\")\n",
    "  else:\n",
    "    print(f\"A imagem mostra um {get_class(label)}. O model prediz {get_class(pred)}.\\n\")\n",
    "\n",
    "\n",
    "# Plotar 5 imagens do lote\n",
    "for i in range(5):\n",
    "  plot_array(data_imgs[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze1-Z77W4yU6"
   },
   "source": [
    "Todas as imagens têm a mesma resolução e os rótulos verdadeiros estão corretos.\n",
    "\n",
    "Vamos começar a servir o modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBgsyhytS6KD"
   },
   "source": [
    "## Sirva seu modelo com o TensorFlow Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1ZVp_VOU7Wu"
   },
   "source": [
    "### Instalar o TensorFlow Serving\n",
    "\n",
    "Você precisará instalar uma versão mais antiga (2.8.0) porque as versões mais recentes são atualmente incompatíveis com o Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygwa9AgRloYy"
   },
   "outputs": [],
   "source": [
    "!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-universal-2.8.0/t/tensorflow-model-server-universal/tensorflow-model-server-universal_2.8.0_all.deb'\n",
    "!dpkg -i tensorflow-model-server-universal_2.8.0_all.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5NrYdQeVm52"
   },
   "source": [
    "### Iniciar a execução do TensorFlow Serving\n",
    "\n",
    "É aqui que começamos a executar o TensorFlow Serving e carregamos nosso modelo.  Depois que ele for carregado, poderemos começar a fazer solicitações de inferência usando REST.  Há alguns parâmetros importantes:\n",
    "\n",
    "* `rest_api_port`: A porta que você usará para solicitações REST.\n",
    "* `model_name`: Você o usará no URL das solicitações REST.  Pode ser qualquer coisa. Nesse caso, é usado `animal_classifier`.\n",
    "* `model_base_path`: É o caminho para o diretório em que você salvou o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUgp3vUdU5GS"
   },
   "outputs": [],
   "source": [
    "# Defina uma variável env com o caminho para onde o modelo é salvo\n",
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJDhHNJVnaLN"
   },
   "outputs": [],
   "source": [
    "# Ativar o servidor de serviço TF\n",
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=animal_classifier \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G3OJcFx6ts2"
   },
   "source": [
    "Dê uma olhada no final dos registros impressos do meu servidor modelo TF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxbeiOCUUs2z"
   },
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8Vat6xJ61rW"
   },
   "source": [
    "O servidor foi capaz de carregar e servir o modelo com sucesso!\n",
    "\n",
    "Como você vai interagir com o servidor por meio de HTTP/REST, deve apontar as solicitações para `localhost:8501`, como está sendo impresso nos logs acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwg1JKaGXWAg"
   },
   "source": [
    "## Faça uma solicitação ao seu modelo no TensorFlow Serving\n",
    "\n",
    "Neste ponto, você já sabe como são seus dados de teste. Você fará previsões para imagens coloridas de 150x150 em lotes de 32 imagens (representadas por matrizes numéricas) de cada vez.\n",
    "\n",
    "Como o REST espera que os dados estejam no formato JSON e o JSON não é compatível com tipos de dados Python personalizados, como matrizes numpy, primeiro você precisa converter essas matrizes em listas aninhadas.\n",
    "\n",
    "O serviço TF espera um campo chamado `instances` que contém os tensores de entrada para o modelo. Para passar seus dados para o modelo, você deve criar um JSON com seus dados como valor para a chave `instances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dsD7KQG1m-R"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Converter matriz numpy em lista\n",
    "data_imgs_list = data_imgs.tolist()\n",
    "\n",
    "# Create JSON to use in the request\n",
    "data = json.dumps({\"instances\": data_imgs_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReQd4QESIwXN"
   },
   "source": [
    "### Fazer solicitações REST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT3J-lHrhOYQ"
   },
   "source": [
    "Enviaremos uma solicitação de previsão como uma solicitação POST para o ponto de extremidade REST do nosso servidor e passaremos a ele o lote de 32 imagens. \n",
    "\n",
    "Lembre-se de que o endpoint que serve o modelo está localizado em `http://localhost:8501`. No entanto, esse URL ainda precisa de alguns parâmetros adicionais para tratar adequadamente a solicitação. Você deve anexar `v1/models/name-of-your-model:predict` a ele para que o TF serving saiba qual modelo procurar e executar uma tarefa de previsão.\n",
    "\n",
    "Você também deve passar para a solicitação os dados que contêm a lista que representa as 32 imagens, juntamente com um dicionário de cabeçalhos que especifica o tipo de conteúdo que será passado, que, nesse caso, é JSON.\n",
    "\n",
    "Depois de obter uma resposta do servidor, você pode obter as previsões dela inspecionando o campo `predictions` do JSON que a resposta retornou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGvFyuIzW6n6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Definir cabeçalhos com o tipo de conteúdo definido como json\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Capture a resposta fazendo uma solicitação para o URL apropriado com os parâmetros apropriados\n",
    "json_response = requests.post('http://localhost:8501/v1/models/animal_classifier:predict', data=data, headers=headers)\n",
    "\n",
    "# Analisar as previsões a partir da resposta\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "# Imprimir a forma das previsões\n",
    "print(f\"predictions has shape: {np.asarray(predictions).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH2ZComkrTb_"
   },
   "source": [
    "Você pode achar estranho que as previsões tenham retornado 3 valores para cada imagem. No entanto, lembre-se de que a última camada do modelo é uma função `softmax`, portanto, ela retornou um valor para cada uma das classes. Para obter as previsões reais, você precisa encontrar o argumento máximo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3cTuqkpp-m-"
   },
   "outputs": [],
   "source": [
    "# Calcule argmax\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Imprima o formato das predições\n",
    "print(f\"preds has shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sUyQF1ysKH4"
   },
   "source": [
    "Agora você tem uma classe prevista para cada uma das imagens de teste! Muito bom!\n",
    "\n",
    "Para testar a qualidade do desempenho do modelo, vamos plotar as primeiras 10 imagens com os rótulos verdadeiros e previstos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tle4OH2lX6oM"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  plot_array(data_imgs[i], labels[i], preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM0EceLpss1Y"
   },
   "source": [
    "Para fazer mais testes, você pode plotar mais imagens das 32 ou até mesmo tentar gerar um novo lote a partir do gerador e repetir as etapas acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio opcional\n",
    "\n",
    "Tente recriar as etapas acima para o próximo lote de 32 imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insira seu código aqui\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8NYLaYpuSEP"
   },
   "source": [
    "## Solução\n",
    "\n",
    "Se você quiser alguma ajuda, a resposta pode ser encontrada na próxima célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQsIJxyttDqQ"
   },
   "outputs": [],
   "source": [
    "# Obter um lote de 32 imagens junto com seu rótulo verdadeiro\n",
    "data_imgs, labels = next(val_gen_no_shuffle)\n",
    "\n",
    "# Converter matriz numérica em lista\n",
    "data_imgs_list = data_imgs.tolist()\n",
    "\n",
    "# Criar JSON para usar na solicitação\n",
    "data = json.dumps({\"instances\": data_imgs_list})\n",
    "\n",
    "# Capture a resposta fazendo uma solicitação para o URL apropriado com os parâmetros apropriados\n",
    "json_response = requests.post('http://localhost:8501/v1/models/animal_classifier:predict', data=data, headers=headers)\n",
    "\n",
    "# Analisar as previsões a partir da resposta\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "# Calcule argmax\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "  plot_array(data_imgs[i], labels[i], preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5wsVTEssIep"
   },
   "source": [
    "# Conclusão\n",
    "**Parabéns por terminar este laboratório!**\n",
    "\n",
    "Agora você deve ter uma compreensão mais profunda dos aspectos internos do TF serving. No laboratórioanterior, você viu como usar o TFS junto com o Docker. Neste laboratório, você viu como o TFS e o `tensorflow-model-server` funcionam sozinhos. Você também viu como salvar um modelo e a estrutura de um modelo salvo.\n",
    "\n",
    "**Continue assim!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-8NYLaYpuSEP"
   ],
   "name": "C4_W1_Lab_2_TF_Serving.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
