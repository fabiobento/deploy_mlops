{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptado de [Machine Learning in Production](https://www.deeplearning.ai/courses/machine-learning-in-production/) de [Andrew Ng](https://www.deeplearning.ai/)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Servir um modelo com o TensorFlow Serving\n",
    "------------------------\n",
    "\n",
    "Neste laboratório, você dará uma olhada no sistema de fornecimento de modelos da TFX para produção chamado [Tensorflow Serving](https://www.tensorflow.org/tfx/guide/serving). Esse sistema é altamente integrado ao Tensorflow e oferece uma maneira fácil e direta de implantar modelos.\n",
    "\n",
    "Especificamente, você irá:\n",
    "- Aprender a instalar o TF Serving.\n",
    "- Carregar um modelo pré-treinado que classifica cães, pássaros e gatos.\n",
    "- Salve-o seguindo as convenções necessárias para o TF serving.\n",
    "- Rodar um servidor Web usando o TF serving que aceitará solicitações por HTTP.\n",
    "- Ingeragir com seu modelo por meio de uma API REST.\n",
    "- Saiba mais sobre o controle de versão do modelo.\n",
    "\n",
    "Este laboratório se inspira [nesse tutorial oficial do Tensorflow](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), portanto, consulte-o se tiver dúvidas sobre os tópicos abordados aqui.\n",
    "\n",
    "Observe que, diferentemente do último laboratório, você trabalhará com o TF servindo sem usar o Docker. O objetivo é mostrar a você as diferentes maneiras de usar esse sistema de serviço.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXp_5RW_dO7k"
   },
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Guf4H620nSWU"
   },
   "source": [
    "### Baixando os dados\n",
    "\n",
    "Neste laboratório, você não treinará um modelo, mas usará um modelo para obter previsões, por isso precisa de algumas imagens de teste. O modelo que você usará foi originalmente treinado com imagens dos conjuntos de dados *cats and dogs* e  *Caltech birds*. Para solicitar previsões, são fornecidas algumas imagens do conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x02JYzMgfTB"
   },
   "outputs": [],
   "source": [
    "# Baixar as imagens\n",
    "!wget -q https://storage.googleapis.com/mlep-public/course_3/week2/images.zip\n",
    "\n",
    "# Definir o diretório base\n",
    "base_dir = '/tmp/data'\n",
    "\n",
    "# Descompactar as imagens\n",
    "with zipfile.ZipFile('/content/images.zip', 'r') as my_zip:\n",
    "  my_zip.extractall(base_dir)\n",
    "\n",
    "# Salvar os caminhos para as imagens de cada classe\n",
    "dogs_dir = os.path.join(base_dir, 'images/dogs')\n",
    "cats_dir = os.path.join(base_dir,'images/cats')\n",
    "birds_dir = os.path.join(base_dir,'images/birds')\n",
    "\n",
    "# Imprimir a quantidade de imagens de cada classe\n",
    "print(f\"Há {len(os.listdir(dogs_dir))} imagens de cachorros\")\n",
    "print(f\"Há {len(os.listdir(cats_dir))} imagens de gatos\")\n",
    "print(f\"Há {len(os.listdir(birds_dir))} imagens de pássaros\\n\\n\")\n",
    "\n",
    "# Veja exemplos de imagens de cada classe\n",
    "print(\"Exemplo de imagem de gato:\")\n",
    "display(Image(filename=f\"{os.path.join(cats_dir, os.listdir(cats_dir)[0])}\"))\n",
    "print(\"\\nExemplo de imagen de cachorro:\")\n",
    "display(Image(filename=f\"{os.path.join(dogs_dir, os.listdir(dogs_dir)[0])}\"))\n",
    "print(\"\\nExemplo de imagem de pássaro:\")\n",
    "display(Image(filename=f\"{os.path.join(birds_dir, os.listdir(birds_dir)[0])}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aEMMrP1oyfx"
   },
   "source": [
    "Agora que você está familiarizado com os dados com os quais trabalhará, vamos passar para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jAk1ZXqTJqN"
   },
   "source": [
    "### Carregar um modelo pré-treinado\n",
    "\n",
    "O objetivo deste laboratório é demonstrar os recursos do TF serving, portanto, você não investirá tempo treinando um modelo. Em vez disso, você usará um modelo pré-treinado. Esse modelo classifica imagens de pássaros, gatos e cachorros e foi treinado com aumento de imagem para produzir resultados muito bons.\n",
    "\n",
    "Primeiro, faça o download dos arquivos necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJuNJRCDdR6J"
   },
   "outputs": [],
   "source": [
    "!wget -q -P /content/model/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/saved_model.pb\n",
    "!wget -q -P /content/model/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.data-00000-of-00001\n",
    "!wget -q -P /content/model/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv3Rlpvde9g9"
   },
   "source": [
    "Agora, carregue o modelo na memória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQX6BPAVdiwg"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAjBnjuqfGuS"
   },
   "source": [
    "Neste ponto, você pode presumir que treinou o modelo com sucesso. Você pode ignorar os avisos sobre o modelo ter sido treinado em uma versão mais antiga do TensorFlow.\n",
    "\n",
    "Para fins de contexto, esse modelo usa uma arquitetura CNN simples. Dê uma olhada rápida nas camadas que o compõem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWkoEffIdwLQ"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwGPItyphqXT"
   },
   "source": [
    "## Salve seu modelo\n",
    "\n",
    "Para carregar nosso modelo treinado no TensorFlow Serving, primeiro precisamos salvá-lo no formato [SavedModel](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/saved_model).\n",
    "\n",
    "Isso criará um arquivo [protobuf](https://developers.google.com/protocol-buffers) em uma hierarquia de diretórios bem definida e incluirá um número de versão.\n",
    "\n",
    "O [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving) nos permite selecionar qual versão de um modelo, ou \"servível\", queremos usar quando fizermos solicitações de inferência.\n",
    "\n",
    "Cada versão será exportada para um subdiretório diferente no caminho fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0w5Rq8SsgWE6"
   },
   "outputs": [],
   "source": [
    "# Buscar a sessão do Keras e salvar o modelo\n",
    "# A definição da assinatura é definida pelos tensores de entrada e saída,\n",
    "# e armazenada com a chave de serviço padrão\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print(f'export_path = {export_path}\\n')\n",
    "\n",
    "\n",
    "# Salvar o modelo\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLieWFZzqzoC"
   },
   "source": [
    "Um modelo salvo em disco inclui os seguintes arquivos:\n",
    "- `assets`: um diretório que inclui arquivos arbitrários usados pelo grafo TF.\n",
    "- `variables`: um diretório que contém informações sobre os pontos de verificação de treinamento do modelo.\n",
    "- `saved_model.pb`: o arquivo protobuf que representa o programa TF real.\n",
    "\n",
    "Dê uma olhada rápida nesses arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-1ARuKsqDpN"
   },
   "outputs": [],
   "source": [
    "print(f'\\nArquivos do modelo salvos em {export_path }:\\n')\n",
    "!ls -lh {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM7B_RuDYoIj"
   },
   "source": [
    "## Examine seu modelo salvo\n",
    "\n",
    "Usaremos o utilitário de linha de comando `saved_model_cli` para examinar os [MetaGraphDefs](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/MetaGraphDef) (os modelos) e [SignatureDefs](https://www.tensorflow.org/tfx/serving/signature_defs) (os métodos que você pode chamar) em nosso SavedModel.\n",
    "\n",
    "Para maiores detalhes consulte [essa discussão sobre a CLI do SavedModel](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel) no Guia do TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LU4GDF_aYtfQ"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSPWuegUb7Eo"
   },
   "source": [
    "Isso nos diz muito sobre o nosso modelo!\n",
    "\n",
    "Nesse caso, não treinamos explicitamente o modelo, portanto, qualquer informação sobre as entradas e saídas é muito valiosa. \n",
    "\n",
    "Por exemplo, sabemos que esse modelo espera que nossas entradas tenham a forma `(150, 150, 3)`, o que, combinado com o uso de camadas `conv2d`, sugere que esse modelo espera imagens coloridas em uma resolução de `150 por 150`.\n",
    "\n",
    "Além disso, a saída do modelo tem a forma `(3)`, o que sugere uma ativação `softmax` com 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2IJklPdvb4q"
   },
   "source": [
    "## Preparar dados para inferência\n",
    "\n",
    "Agora que você conhece a forma dos dados esperados pelo modelo, é hora de pré-processar as imagens de teste adequadamente. \n",
    "\n",
    "Essas imagens são fornecidas em uma ampla variedade de resoluções, e felizmente o Keras tem o que você precisa com seu [`ImageDataGenerator`](https://keras.io/api/preprocessing/image/).\n",
    "\n",
    "Usando esse objeto, você pode:\n",
    "- Normalizar valores de pixel.\n",
    "- Padronizar resoluções de imagem.\n",
    "- Definir um tamanho de lote para inferência.\n",
    "- E muito mais!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcnU-SjhvYEX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalizar os valores dos pixels\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Apontar para o diretório com as imagens de teste\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/images',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "# Imprimir o rótulo associado a cada classe\n",
    "print(f\"Os rótulos de cada classe no gerador de testes são: {val_gen_no_shuffle.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvw4doL20UeK"
   },
   "source": [
    "Como esse objeto é um [gerador](https://wiki.python.org/moin/Generators), você pode obter um lote de imagens e rótulos usando a função `next`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGaajm_F0Jd8"
   },
   "outputs": [],
   "source": [
    "# Obtenha um lote de 32 imagens junto com seu rótulo verdadeiro\n",
    "data_imgs, labels = next(val_gen_no_shuffle)\n",
    "\n",
    "# Verifique os formatos\n",
    "print(f\"data_imgs tem formato: {data_imgs.shape}\")\n",
    "print(f\"os rótulos tem o formato: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MH3YPjZ1D8I"
   },
   "source": [
    "As expected `data_imgs` is an array containing 32 colored images of 150x150 resolution. In a similar fashion `labels` has the true label for each one of these 32 images.\n",
    "\n",
    "To check that everything is working properly, do a sanity check to plot the first 5 images in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31yuK5RTvgkT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "# Returns string representation of each class\n",
    "def get_class(index):\n",
    "  if index == 0:\n",
    "    return \"bird\"\n",
    "  elif index == 1:\n",
    "    return \"cat\"\n",
    "  elif index == 2:\n",
    "    return \"dog\"\n",
    "  return None\n",
    "\n",
    "\n",
    "# Plots a numpy array representing an image\n",
    "def plot_array(array, label, pred=None):\n",
    "  array = np.squeeze(array)\n",
    "  img = array_to_img(array)\n",
    "  display(img)\n",
    "  if pred is None:\n",
    "    print(f\"Image shows a {get_class(label)}.\\n\")\n",
    "  else:\n",
    "    print(f\"Image shows a {get_class(label)}. Model predicted it was {get_class(pred)}.\\n\")\n",
    "\n",
    "\n",
    "# Plot the first 5 images in the batch\n",
    "for i in range(5):\n",
    "  plot_array(data_imgs[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze1-Z77W4yU6"
   },
   "source": [
    "All images have the same resolution and the true labels are correct.\n",
    "\n",
    "Let's jump to serving the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBgsyhytS6KD"
   },
   "source": [
    "## Serve your model with TensorFlow Serving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1ZVp_VOU7Wu"
   },
   "source": [
    "### Install TensorFlow Serving\n",
    "\n",
    "You will need to install an older version (2.8.0) because more recent versions are currently incompatible with Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygwa9AgRloYy"
   },
   "outputs": [],
   "source": [
    "!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-universal-2.8.0/t/tensorflow-model-server-universal/tensorflow-model-server-universal_2.8.0_all.deb'\n",
    "!dpkg -i tensorflow-model-server-universal_2.8.0_all.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5NrYdQeVm52"
   },
   "source": [
    "### Start running TensorFlow Serving\n",
    "\n",
    "This is where we start running TensorFlow Serving and load our model.  After it loads we can start making inference requests using REST.  There are some important parameters:\n",
    "\n",
    "* `rest_api_port`: The port that you'll use for REST requests.\n",
    "* `model_name`: You'll use this in the URL of REST requests.  It can be anything. For this case `animal_classifier` is used.\n",
    "* `model_base_path`: This is the path to the directory where you've saved your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUgp3vUdU5GS"
   },
   "outputs": [],
   "source": [
    "# Define an env variable with the path to where the model is saved\n",
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJDhHNJVnaLN"
   },
   "outputs": [],
   "source": [
    "# Spin up TF serving server\n",
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=animal_classifier \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G3OJcFx6ts2"
   },
   "source": [
    "Take a look at the end of the logs printed out my TF model server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxbeiOCUUs2z"
   },
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8Vat6xJ61rW"
   },
   "source": [
    "The server was able to succesfully load and serve the model!\n",
    "\n",
    "Since you are going to interact with the server through HTTP/REST, you should point the requests to `localhost:8501` as it is being printed in the logs above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwg1JKaGXWAg"
   },
   "source": [
    "## Make a request to your model in TensorFlow Serving\n",
    "\n",
    "At this point you already know how your test data looks like. You are going to make predictions for colored images of 150x150 in batches of 32 images (represented by numpy arrays) at a time.\n",
    "\n",
    "Since REST expects the data to be in JSON format and JSON does not support custom Python data types such as numpy arrays you first need to convert these arrays into nested lists.\n",
    "\n",
    "TF serving expects a field called `instances` which contains the input tensors for the model. To pass in your data to the model you should create a JSON with your data as value for the key `instances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dsD7KQG1m-R"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert numpy array to list\n",
    "data_imgs_list = data_imgs.tolist()\n",
    "\n",
    "# Create JSON to use in the request\n",
    "data = json.dumps({\"instances\": data_imgs_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReQd4QESIwXN"
   },
   "source": [
    "### Make REST requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT3J-lHrhOYQ"
   },
   "source": [
    "We'll send a predict request as a POST request to our server's REST endpoint, and pass it the batch of 32 images. \n",
    "\n",
    "Remember that the endpoint that serves the model is located at `http://localhost:8501`. However this URL still needs some additional parameters to properly handle the request. You should append `v1/models/name-of-your-model:predict` to it so TF serving knows which model to look for and to perform a predict task.\n",
    "\n",
    "You should also pass to the request the data containing the list that represents the 32 images along with a headers dictionary that specifies the type of content that will be passed, which is JSON in this case.\n",
    "\n",
    "After you get a response from the server you can get the predictions out of it by inspecting the `predictions` field of the JSON that the response returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGvFyuIzW6n6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define headers with content-type set to json\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Capture the response by making a request to the appropiate URL with the appropiate parameters\n",
    "json_response = requests.post('http://localhost:8501/v1/models/animal_classifier:predict', data=data, headers=headers)\n",
    "\n",
    "# Parse the predictions out of the response\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "# Print shape of predictions\n",
    "print(f\"predictions has shape: {np.asarray(predictions).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH2ZComkrTb_"
   },
   "source": [
    "You might think it is weird that the predictions returned 3 values for each image. However, remember that the last layer of the model is a `softmax` function, so it returned a value for each one of the class. To get the actual predictions you need to find the maximum argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3cTuqkpp-m-"
   },
   "outputs": [],
   "source": [
    "# Compute argmax\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print shape of predictions\n",
    "print(f\"preds has shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sUyQF1ysKH4"
   },
   "source": [
    "Now you have a predicted class for each one of the test images! Nice!\n",
    "\n",
    "To test how good the model is performing let's plot the first 10 images along with the true and predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tle4OH2lX6oM"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  plot_array(data_imgs[i], labels[i], preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM0EceLpss1Y"
   },
   "source": [
    "To do some further testing you can plot more images out of the 32 or even try to generate a new batch from the generator and repeat the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try to recreating the steps above for the next batch of 32 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8NYLaYpuSEP"
   },
   "source": [
    "## Solution\n",
    "\n",
    "If you want some help, the answer can be found in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQsIJxyttDqQ"
   },
   "outputs": [],
   "source": [
    "# Get a batch of 32 images along with their true label\n",
    "data_imgs, labels = next(val_gen_no_shuffle)\n",
    "\n",
    "# Convert numpy array to list\n",
    "data_imgs_list = data_imgs.tolist()\n",
    "\n",
    "# Create JSON to use in the request\n",
    "data = json.dumps({\"instances\": data_imgs_list})\n",
    "\n",
    "# Capture the response by making a request to the appropiate URL with the appropiate parameters\n",
    "json_response = requests.post('http://localhost:8501/v1/models/animal_classifier:predict', data=data, headers=headers)\n",
    "\n",
    "# Parse the predictions out of the response\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "# Compute argmax\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "  plot_array(data_imgs[i], labels[i], preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5wsVTEssIep"
   },
   "source": [
    "# Conclusion\n",
    "**Congratulations on finishing this ungraded lab!**\n",
    "\n",
    "Now you should have a deeper understanding of TF serving's internals. In the previous ungraded lab you saw how to use TFS alongside with Docker. In this one you saw how TFS and `tensorflow-model-server` worked on their own. You also saw how to save a model and the structure of a saved model.\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-8NYLaYpuSEP"
   ],
   "name": "C4_W1_Lab_2_TF_Serving.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
